<!DOCTYPE html>
<html>
<html lang="en">

  <head>
      <link href="css/personal.css" rel="stylesheet">
      <script src="http://code.jquery.com/jquery-1.11.3.min.js"></script>
      <script type="text/javascript" src="js/personal.js"></script>
  </head>


  <body>

  <h1>projects</h1>

   <div id="nav" class='links' align="right">
        <ul style="list-style-type:none">
          <li><span><div class="nav-links"><a href="index.html">home</a></div></span></li>
          <li><span><div class="nav-links"><a href="about.html">about</a></div></span></li>
          <li><span><div class="nav-links"><a href="projects.html">projects</a></div></span></li>
          <li><span><div class="nav-links"><a href="publications.html">publications</a></div></span></li>
          <li><span><div class="nav-links"><a href="mailto:juliawilkins88@gmail.com">contact</a></div></span></li>
          <li>
            <div id="image link" class="imlink">
              <span><a href="img/jw_resume_gs.pdf"><img src="img/resume-icon.png" width="30" height="30"></a></span>
            </div>
          </li>
          <li>
            <div id="image link" class="imlink">
              <span><a href="http://github.com/jlw365"><img src="img/mark.png" width="30" height="30"></a></span>
            </div>
          </li>
        </ul>
  </div>

<h3-project-section-header><b>research</b></h3-project-section-header>

<br><br>
<h3-project-header><b>VocalSet</b></h3-project-header>
    <div class="project-text">
      <div class="project-img">
        <br>
        <img src="img/vocalset2.png" alt="Avatar" class="image" width="100" height="600">
      </div>
      <br>
        <b> Northwestern University, Interactive Audio Lab - 2018 </b>
        <br><br>
        <b>VocalSet: A Singing Voice Dataset</a>. Julia Wilkins, Prem Seetharaman, Alison Wahl, Bryan Pardo. <i>In proceedings of International Society for Music Information Retrieval (ISMIR) 2018.</i></b>
        <br>
    
        <br>
        <div class="project-text-headers">
          <b>Overview</b>
        </div>
        VocalSet is a singing voice dataset consisting of 10.1 hours of monophonic recorded audio of professional singers demonstrating both standard and extended vocal techniques on all 5 vowels. This dataset is designed to further research in the music information retrieval and machine listening spaces by providing a robust, large dataset of professional-grade vocal samples. In addition to the dataset creation, we experimented with early applications using this dataset including singer classification, vocal technique identification, and vocal style transfer.
        <br><br>
        <div class="project-text-headers">
          <b>Resources</b>
        </div>
        <ul>
          <li><a href="https://interactiveaudiolab.github.io/demos/vocalset" style="color:#2777f7">Demo Website</a></li>
          <li><a href="https://zenodo.org/record/1442513#.X8QaGJNKgkU" style="color:#2777f7">Zenodo Dataset</a></li>
          <li><a href="http://ismir2018.ircam.fr/doc/pdfs/114_Paper.pdf" style="color:#2777f7">Publication</a>(In proceedings of ISMIR 2018)</li>
        </ul>
    
        <div class="project-text-headers">
          <b>Technical Skills Used</b>
        </div>
        <ul>
          <li>Python (Scikit-Learn, Tensorflow, PyTorch)</li>
        </ul>
      </div>

<br><br>
<h3-project-header><b>MedleyDB 2.0</b></h3-project-header>
      <div class="project-text">
        <!-- <div class="project-img">
          <br>
          <img src="img/vocalset2.png" alt="Avatar" class="image" width="100" height="600">
        </div> -->
        <br>
          <b> New York University, Music and Audio Research Lab - 2016</b>
          <br><br>
          <b>Medley DB 2.0: New Data and a System for Sustainable Data Collection</a>. Rachel Bittner, Julia Wilkins, Hanna Yip, Juan Bello. <i> Late Breaking Demo at International Society for Music Informational Retrieval (ISMIR) 2016</i>.</b>
          <br>
      
          <br>
          <div class="project-text-headers">
            <b>Overview</b>
          </div>
              MedleyDB 2.0 is the second iteration of a dataset of multitrack recordings created to support Music Information Retrieval (MIR) research. This work includes not only the dataset itself (with improved annotations and quantity of content), but tools for sustainable data collection and maintence of this dataset.
          <br><br>
          <div class="project-text-headers">
            <b>Resources</b>
          </div>
          <ul>
            <li><a href="https://medleydb.weebly.com/" style="color:#2777f7">Project Website</a></li>
            <li><a href="https://wp.nyu.edu/ismir2016/wp-content/uploads/sites/2294/2016/08/bittner-medleydb.pdf" style="color:#2777f7">Publication</a> (Late Breaking Demo at ISMIR 2016)</li>
            <li><a href="https://github.com/marl/medley-de-bugger" style="color:#2777f7">Medley DeBugger</a> (Python application for cleaning audio recordings prior to dataset upload)</li>
          </ul>
      
          <div class="project-text-headers">
            <b>Technical Skills Used</b>
          </div>
          <ul>
            <li>Python (<a href="https://github.com/librosa/librosa" style="color:#2777f7">Librosa</a>, <a href="https://github.com/rabitt/pysox" style="color:#2777f7"> PySox</a>, Scikit-Learn)</li>
          </ul>
        </div>

<br><br>
<h3-project-section-header><b>music technology</b></h3-project-section-header>
<br><br>
<h3-project-header><b>MusiCube</b></h3-project-header>
    <br><br>
      <div class="project-text">
          <iframe width="560" height="315" src="https://www.youtube.com/embed/kmGIZe5D97s" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>

        <br><br>
          <b> Northwestern University, EECS 397: Digital Luthier, Professor Bryan Pardo - 2018</b>
          <br>
      
          <br>
          <div class="project-text-headers">
            <b>Overview</b>
          </div>
          MusiCube is a Max/MSP application that combines audio and visual processing to create an intriguing musical experience for any user. The core of the application is a 3D cube that contains multiple naturally bouncing balls which sound different musical notes when they collide with eachother and strike different "wall" surfaces around the cube. I have also included an interface for users to control parameters such as the pitches of the collisions, number and size of balls, and physical attributes of the balls (restitution/"bounce"), among other attributes. 
        <br><br>
          <div class="project-text-headers">
            <b>Resources</b>
          </div>
          <ul>
            <li><a href="https://jlw365.github.io/musicube.html" style="color:#2777f7">Deep Dive Page</a></li>
          </ul>
      
          <div class="project-text-headers">
            <b>Technical Skills Used</b>
          </div>
          <ul>
            <li>Max/MSP</li>
            <li> Jitter (jit.phys specifically)</li>
          </ul>

      </div>
      
<br><br>
<h3-project-header><b>Max/MSP & openFrameworks Projects</b></h3-project-header>
  <br><br>
<div class="project-text">
  Throughout my undergraduate studies at Northwestern and during my study abroad experience at Goldsmiths, University of London, I worked on a variety of audio synthesis and electro-acoustic music composition projects. Here are some of the demo videos I put together through these classes:
<br><br>
<b>Max/MSP</b>
  <ul>
      <li><a href="https://www.youtube.com/watch?v=7BXiwIXJwEg" style="color:#2777f7">L-System Chord Sequencer</a></li>
      <li><a href="https://www.youtube.com/watch?v=55um2w-9Ls0" style="color:#2777f7">Fiddle Delay Shifter Patch</a></li>
      <li><a href="https://www.youtube.com/watch?v=kmGIZe5D97s" style="color:#2777f7"> MusicCube</a>(detailed above)</li>
  </ul>
<br>
<b>openFrameworks</b>
<ul>
    <li><a href="https://www.youtube.com/watch?v=6h-M6mxII-k" style="color:#2777f7">Interactive FM/AM Visualizer</a></li>
    <li><a href="https://www.youtube.com/watch?v=1ud4pVj1_Cc" style="color:#2777f7">Drum Machine Visualizer</a></li>
    <li><a href="https://www.youtube.com/watch?v=5D_1CGZ6FAE" style="color:#2777f7">Bouncing Ball Synthesizer</a></li>
    <li><a href="https://www.youtube.com/watch?v=Cw844dcTti0" style="color:#2777f7">Debate Vocal Manipulation</a></li>
</ul>

</div>


<br><br>
<h3-project-section-header><b>software engineering</b></h3-project-section-header>
<br><br>
<h3-project-header><b>PurSIST</b></h3-project-header>
  <div class="project-text">
  <br><br>
    <b> Northwestern University, Spring 2018, <a href="http://www.cs.northwestern.edu/academics/courses/394/" style="color:#2777f7">394: Software Project Management and Development</a>, Professor Christopher Riesbeck</b>

    <br><br>
    <div class="project-text-headers">
      <b>Overview</b>
    </div>
    PurSIST (Stakeholder Input Synthesis Tool) is a web application tool designed to improve lab meeting productivity by providing an interface for meeting attendees to submit problem statements such that the meeting organizers can then tag the cards with causal variables, leading to a better visualization and organization system for lab issues. This app was initially deployed and hosted on Heroku but is currently unavailable due to lack of funding to continue hosting the application. 
    <br><br>
    <div class="project-text-headers">
        <b>Resources</b>
      </div>
      <ul>
        <li><a href="https://github.com/jlw365/pursist" style="color:#2777f7">Project Github</a>
        </li>
      </ul>

    <div class="project-text-headers">
      <b>Technical Skills Used</b>
    </div>
    <ul>
      <li>PostgreSQL</li>
      <li>Express, Javascript</li>
      <li>HTML/Pug, CSS</li>
      <li>Agile Development Practices</li>
      <li>Client and Large Group Management and Communication</li>
    </ul>

    <div class="table-project-img">
        <table>
        <tr>
        <td>
            <img src="img/pursist-enter-card.png" alt="Avatar" class="image">
          </td>
          <td>Meeting attendees can enter problem statements into this standardized template.</td></tr>

        <tr>
          <td>
            <img src="img/pursist-full-cards.png" alt="Avatar" class="image">
          </td>
          <td>Meeting organizers can view the submitted problems and tag them to create a causal diagram about the overall problems on the cards.</td>

        </tr>
        </table>
      </div>
</div>

</div>

  </body>
</html>
